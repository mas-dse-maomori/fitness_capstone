{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ujson\n",
    "import pprint\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# For displaying google maps\n",
    "import gmplot\n",
    "from IPython.display import IFrame\n",
    "\n",
    "# Second (better?) google map, only inline so far\n",
    "import gmaps\n",
    "\n",
    "# For summary stats\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "# For testing a subset of the data\n",
    "from copy import deepcopy\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/patrickmulrooney/Downloads/endomondoHR/endoHRParsed_no_outliers.json\n"
     ]
    }
   ],
   "source": [
    "# Read config from local file\n",
    "GMAP_API_KEY = None\n",
    "\n",
    "sys.path.append('/Users/patrickmulrooney/Desktop/')\n",
    "import capstone_config\n",
    "\n",
    "_file = capstone_config._INPUT_FILE\n",
    "GMAP_API_KEY = capstone_config._GMAP_API_KEY\n",
    "\n",
    "gmaps.configure(api_key=GMAP_API_KEY)\n",
    "\n",
    "print _file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing auto adding time output to all cells\n",
    "'''\n",
    "#To install...\n",
    "wget https://raw.githubusercontent.com/cpcloud/ipython-autotime/master/autotime.py\n",
    "#Make available via\n",
    "jupyter nbextension install /Users/patrickmulrooney/class/notebooks/pjmulroo/DSECapstone/autotime.py\n",
    "'''\n",
    " \n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 62.1 ms\n"
     ]
    }
   ],
   "source": [
    "def log_progress(sequence, every=None, size=None):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{index} / ?'.format(index=index)\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{index} / {size}'.format(\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = str(index or '?')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with data already parsed from LoadData - 1 notebook\n",
    "## Load parsed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10min 51s\n"
     ]
    }
   ],
   "source": [
    "#time: 12min 44s\n",
    "# Set via config file\n",
    "# Full dataset\n",
    "#_file = \"/Users/patrickmulrooney/Downloads/endomondoHR/endoHRParsed.json\"\n",
    "# Full dataset, outliers removed\n",
    "#_file = \"/Users/patrickmulrooney/Downloads/endomondoHR/endoHRParsed_no_outliers.json\"\n",
    "# Partial dataset\n",
    "#_file = \"/Users/patrickmulrooney/Downloads/endomondoHR/endoHRParsed_10k.json\"\n",
    "# Partial dataset, outliers removed\n",
    "#_file = \"/Users/patrickmulrooney/Downloads/endomondoHR/endoHRParsed_no_outliers_10k.json\"\n",
    "\n",
    "endoHR = []\n",
    "\n",
    "with open(_file, 'r') as f:\n",
    "    endoHR += ujson.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of import: 251774\n",
      "time: 8.6 ms\n"
     ]
    }
   ],
   "source": [
    "print \"Length of import: %s\"%(len(endoHR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Used between cells\n",
    "\n",
    "# List of all the exercise types in the dataset\n",
    "exercise_types = {}\n",
    "\n",
    "# Keys in each record\n",
    "all_keys = []\n",
    "\n",
    "\n",
    "series_keys = { True: ['timestamp', 'heart_rate', 'altitude', 'latitude', 'longitude', 'speed' ], \\\n",
    "               False: ['timestamp', 'heart_rate', 'altitude', 'latitude', 'longitude'] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See what keys still remain.\n",
    "sports = {}\n",
    "count = 0\n",
    "for _endoHR in endoHR:\n",
    "    all_keys += _endoHR.keys()\n",
    "    _sport = _endoHR[ 'sport' ]\n",
    "    try:\n",
    "        sports[_sport] += 1\n",
    "    except:\n",
    "        sports[_sport] = 1\n",
    "        \n",
    "    if _sport not in exercise_types.keys():\n",
    "        exercise_types[_sport] = count\n",
    "        count += 1\n",
    "\n",
    "# Drop dupes\n",
    "all_keys = set( all_keys )\n",
    "\n",
    "sports2 = []\n",
    "\n",
    "for k,v in sports.iteritems():\n",
    "    sports2.append((k,v))\n",
    "\n",
    "print \"What keys remain?\"\n",
    "pp.pprint( all_keys )\n",
    "\n",
    "print \"\"\n",
    "print \"\"\n",
    "\n",
    "print \"What sports?\"\n",
    "pp.pprint( sorted(sports2, key=itemgetter(1), reverse=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seriesLength = []\n",
    "\n",
    "for _endoHR in log_progress(endoHR, every=5):\n",
    "\n",
    "    # For debugging purposes, get a record of length of series for histogram\n",
    "    _seriesLen = len(_endoHR['series'])\n",
    "    seriesLength.append(_seriesLen)\n",
    "    \n",
    "plt.hist(seriesLength, bins=50, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "Looks like there must be some sort of limit with the HR stuff of 500 records per exercise, or the api not returning more than that. Need to look at this further.\n",
    "\n",
    "### Get deltas of timestamps and speed in series. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for _endoHR in log_progress(endoHR, every=1):\n",
    "    _max_time_delta = 0\n",
    "    \n",
    "    _timestamps = [item[0] for item in _endoHR['series']]\n",
    "    _endoHR['end_start_delta'] = max(_timestamps) - min(_timestamps)\n",
    "\n",
    "    for i,_cur in enumerate(_timestamps[:-2]):\n",
    "        _next = _timestamps[i+1]\n",
    "        _diff = _next - _cur\n",
    "        if _diff > _max_time_delta:\n",
    "            _max_time_delta = _diff\n",
    "    \n",
    "    _endoHR['max_time_delta'] = _max_time_delta\n",
    "    \n",
    "    if _endoHR['speed_included']:\n",
    "        _max_speed_delta = 0\n",
    "        _max_speed = 0\n",
    "        \n",
    "        _speeds = [item[5] for item in _endoHR['series']]\n",
    "\n",
    "        for i,_cur in enumerate(_speeds[:-2]):\n",
    "            _next = _speeds[i+1]\n",
    "            _diff = _next - _cur\n",
    "            \n",
    "            if _diff > _max_speed_delta:\n",
    "                _max_speed_delta = _diff\n",
    "                \n",
    "            if _cur > _max_speed:\n",
    "                _max_speed = _cur\n",
    "    \n",
    "        _endoHR['max_speed'] = _max_speed\n",
    "        _endoHR['max_speed_delta'] = _max_speed_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See how long \n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "_esd = sorted([(item['end_start_delta']/60) for item in endoHR])\n",
    "\n",
    "print pd.Series(_esd).describe()\n",
    "\n",
    "# Based on summary stats, lets only keep those less than 6 hours. Beyond that is crazy.\n",
    "#_esd = [_i for _i in _esd if _i < 360]\n",
    "_esd = [_i for _i in _esd if _i < 2880]\n",
    "\n",
    "\n",
    "plt.hist(_esd,bins=200,log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out where these people are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#time: 9min 12s\n",
    "lat_longs = []\n",
    "\n",
    "for _endoHR in log_progress(endoHR, every=1):\n",
    "    _series = _endoHR['series'][0]\n",
    "    lat_longs.append([_series[3], _series[4], _endoHR['sport']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#time: 7.94 s\n",
    "# Write the lat longs to file, need to figure out how to map. Probably google maps and kml, try basemap below.\n",
    "\n",
    "target = open(\"/tmp/lat_longs.txt\", 'w')\n",
    "for i in lat_longs:\n",
    "    target.write(\"%s,%s\\n\"%(i[0],i[1]))\n",
    "    \n",
    "target.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lats = [ _i[0] for _i in lat_longs ]\n",
    "lons = [ _i[1] for _i in lat_longs ]\n",
    "sport_type = [ exercise_types[_i[2]] for _i in lat_longs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Americas\n",
    "plt.figure(figsize=(12,12))\n",
    "m = Basemap(width=15000000,height=20000000,resolution='i',projection='stere', lat_ts=0,lat_0=10,lon_0=-80.)\n",
    "x, y = m(lons,lats)\n",
    "m.drawmapboundary(fill_color='#99ffff')\n",
    "m.fillcontinents(color='#cc9966',lake_color='#99ffff',zorder=0)\n",
    "m.scatter(x,y,1, marker='o')\n",
    "m.drawcountries()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Europe, Africa, Asia, etc\n",
    "plt.figure(figsize=(12,12))\n",
    "m = Basemap(width=30000000,height=20000000,resolution='i',projection='stere', lat_ts=0,lat_0=10,lon_0=80.)\n",
    "x, y = m(lons,lats)\n",
    "m.drawmapboundary(fill_color='#99ffff')\n",
    "m.fillcontinents(color='#cc9966',lake_color='#99ffff',zorder=0)\n",
    "m.scatter(x,y,1, marker='o')\n",
    "m.drawcountries()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#US\n",
    "lat=40\n",
    "lon=-100\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "m = Basemap(width=5000000,height=3000000,resolution='h',projection='stere', lat_ts=0,lat_0=lat,lon_0=lon)\n",
    "x, y = m(lons,lats)\n",
    "m.drawmapboundary(fill_color='#99ffff')\n",
    "m.fillcontinents(color='#cc9966',lake_color='#99ffff',zorder=0)\n",
    "m.scatter(x,y,1, marker='o')\n",
    "m.drawcountries()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Europe\n",
    "lat=50\n",
    "lon=10\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "m = Basemap(width=5000000,height=3000000,resolution='h',projection='stere', lat_ts=0,lat_0=lat,lon_0=lon)\n",
    "x, y = m(lons,lats)\n",
    "m.drawmapboundary(fill_color='#99ffff')\n",
    "m.fillcontinents(color='#cc9966',lake_color='#99ffff',zorder=0)\n",
    "m.scatter(x,y,1, marker='o')\n",
    "m.drawcountries()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "lats_rounded = [ float(\"{0:.4f}\".format(_i)) for _i in lats ]\n",
    "lons_rounded = [ float(\"{0:.4f}\".format(_i)) for _i in lons ]\n",
    "sport_type = [ exercise_types[_i[2]] for _i in lat_longs ]\n",
    "\n",
    "# # declare the center of the map, and how much we want the map zoomed in\n",
    "# gmap = gmplot.GoogleMapPlotter(0, 0, 2)\n",
    "# # plot heatmap\n",
    "# gmap.heatmap(lats_rounded, lons_rounded)\n",
    "\n",
    "# gmap.draw(\"/tmp/workout_heatmap.html\")\n",
    "\n",
    "m = gmaps.Map()\n",
    "heatmap_layer = gmaps.Heatmap(data=zip(lats_rounded, lons_rounded))\n",
    "m.add_layer(heatmap_layer)\n",
    "\n",
    "heatmap_layer.max_intensity = 90\n",
    "heatmap_layer.point_radius = 3\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "* Really popular in Copenhagen. Endomundo was founded in Copenhagen.\n",
    "* Really popular in Bangkok. No idea why\n",
    "\n",
    "## Figure out who works out the most, and how much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#time: 9min 51s\n",
    "_uid_freq = {}\n",
    "for _endoHR in log_progress(endoHR, every=5):\n",
    "    try:\n",
    "        _uid_freq[_endoHR['userId']] += 1\n",
    "    except:\n",
    "        _uid_freq[_endoHR['userId']] = 1\n",
    "        \n",
    "_uid_freq2 = []\n",
    "\n",
    "for k,v in _uid_freq.iteritems():\n",
    "    _uid_freq2.append((k,v))\n",
    "\n",
    "print \"Top 100 users\"\n",
    "pp.pprint( sorted(_uid_freq2, key=itemgetter(1), reverse=True)[:100] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(sorted([_i[1] for _i in _uid_freq2]),bins=100,log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What sports did the top 100 most active users do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#time: 9min 51s\n",
    "_top_participants = [ _i[0] for _i in sorted(_uid_freq2, key=itemgetter(1), reverse=True)[:100]]\n",
    "\n",
    "_uid_freq_detail = {}\n",
    "for _endoHR in log_progress(endoHR, every=1):\n",
    "    if not _endoHR['userId'] in _uid_freq_detail.keys():\n",
    "        _uid_freq_detail[_endoHR['userId']] = {}\n",
    "    if _endoHR['sport'] in _uid_freq_detail[_endoHR['userId']].keys():\n",
    "        _uid_freq_detail[_endoHR['userId']][_endoHR['sport']] += 1\n",
    "    else:\n",
    "        _uid_freq_detail[_endoHR['userId']][_endoHR['sport']] = 1\n",
    "        \n",
    "_uid_freq_detail2 = []\n",
    "\n",
    "for k,v in _uid_freq_detail.iteritems():\n",
    "    _uid_freq_detail2.append((k,v))\n",
    "\n",
    "sorted(_uid_freq_detail2, key=lambda x: sum(x[1].values()) , reverse=True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets figure out where user 4997910 lives / works.\n",
    "# So many bike commutes probably will be able top guess based on heat map\n",
    "\n",
    "_user = []\n",
    "\n",
    "for _i in endoHR:\n",
    "    if _i['userId'] == 3714939:\n",
    "        _user.append(_i['series'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_user = [ item for sublist in _user for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(_user)\n",
    "_user[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#_user_lat = [round(_i[3],3) for _i in _user]\n",
    "#_user_long = [round(_i[4],3) for _i in _user]\n",
    "_user_lat_long = [(round(_i[3],3),round(_i[4],3)) for _i in _user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_weighted_user_lat_long_dict = {}\n",
    "for _i in _user:\n",
    "    _tmp_lat_long = (round(_i[3],3),round(_i[4],3))\n",
    "    \n",
    "    if _tmp_lat_long not in _weighted_user_lat_long_dict:\n",
    "        _weighted_user_lat_long_dict[_tmp_lat_long] = 1\n",
    "    else:\n",
    "        _weighted_user_lat_long_dict[_tmp_lat_long] += 1\n",
    "\n",
    "_weighted_user_lat_long = []\n",
    "for k, v in _weighted_user_lat_long_dict.iteritems():\n",
    "    _weighted_user_lat_long.append((k[0],k[1],v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gmap = gmplot.GoogleMapPlotter(0, 0, 2)\n",
    "# # plot heatmap\n",
    "# gmap.heatmap(_user_lat, _user_long)\n",
    "\n",
    "# gmap.draw(\"/tmp/workout_heatmap_3714939.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = gmaps.Map()\n",
    "heatmap_layer = gmaps.WeightedHeatmap(data=_weighted_user_lat_long)\n",
    "m.add_layer(heatmap_layer)\n",
    "\n",
    "heatmap_layer.max_intensity = 90\n",
    "heatmap_layer.point_radius = 3\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Was able to determine where this user likely lives, and where they likely work\n",
    "\n",
    "### Lets try the top 5 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# _top_users = [ _j[0] for _j  in sorted(_uid_freq_detail2, key=lambda x: sum(x[1].values()) , reverse=True)[:10]]\n",
    "\n",
    "# for _j in log_progress(_top_users):\n",
    "#     _user = []\n",
    "#     for _i in endoHR:\n",
    "#         if _i['userId'] == _j:\n",
    "#             _user.append(_i['series'])\n",
    "\n",
    "#     # Flatten\n",
    "#     _user = [ item for sublist in _user for item in sublist]\n",
    "#     _user_lat = [_i[3] for _i in _user]\n",
    "#     _user_long = [_i[4] for _i in _user]\n",
    "\n",
    "#     gmap = gmplot.GoogleMapPlotter(0, 0, 2)\n",
    "#     # plot heatmap\n",
    "#     gmap.heatmap(_user_lat, _user_long)\n",
    "#     # map markers\n",
    "#     #gmap.scatter(_user_lat, _user_long, '#3B0B39', size=40, marker=False)\n",
    "#     #gmap.scatter(_user_lat, _user_long, 'k', marker=True)\n",
    "#     # Not sure..\n",
    "#     #gmap.plot(_user_lat, _user_long, 'cornflowerblue', edge_width=10)\n",
    "\n",
    "\n",
    "#     gmap.draw(\"/tmp/workout_heatmap_%s.html\"%_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets get summary stats of series time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "endoHR_stats = []\n",
    "\n",
    "for _endoHR in log_progress(endoHR, every=1):\n",
    "    _summary = { 'average_diff': 0, 'median_diff': [], 'delta': 0, }\n",
    "    \n",
    "    _timestamps = [item[0] for item in _endoHR['series']]\n",
    "    \n",
    "    # only concern ourselves with those more than 60 timestamps in the activity.\n",
    "    if len(_timestamps) < 60:\n",
    "        continue\n",
    "    \n",
    "    _summary['delta'] = _timestamps[-1] - _timestamps[0]\n",
    "    \n",
    "    \n",
    "    for _i, _timestamp in enumerate(_timestamps[:-2]):\n",
    "        _diff = _timestamps[_i+1] - _timestamps[_i]\n",
    "        _summary['average_diff'] += _diff\n",
    "        _summary['median_diff'].append(_diff)\n",
    "        \n",
    "    try:\n",
    "        _summary['average_diff'] = _summary['average_diff'] / len(_timestamps)\n",
    "        _summary['median_diff'] = sorted(_summary['median_diff'])[len(_timestamps)/2]\n",
    "    except:\n",
    "        print len(_timestamps)\n",
    "    endoHR_stats.append(_summary)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "endoHR_stats\n",
    "print \"Average\"\n",
    "print scipy.stats.describe([_i['average_diff'] for _i in endoHR_stats])\n",
    "\n",
    "print \"\"\n",
    "print \"Median\"\n",
    "print scipy.stats.describe([_i['median_diff'] for _i in endoHR_stats])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heartrate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_heart_rates = [ item[1] for sublist in endoHR for item in sublist['series']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(sorted(_heart_rates),bins=100, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# heart rate summary stats\n",
    "print scipy.stats.describe(_heart_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like there is a fair amount of garbage in the heart rate data. Min = -706, Max = 1001. Lets set some limits.\n",
    "\n",
    "from: https://www.reddit.com/r/askscience/comments/1opolp/what_is_the_fastest_the_average_human_heart_could/\n",
    "\n",
    "```\n",
    "The absolute refractory period of cardiac muscle is between 250 and 300 ms. That means cardiac contractions are physiologically limited to 200-240 beats per minute.\n",
    "```\n",
    "\n",
    "#### So lets set a max of 250 and min of 40. Below that likely to be error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_bad_heart_rates = [ _i for _i in _heart_rates if _i not in range(40,250)]\n",
    "_heart_rates = [ _i for _i in _heart_rates if _i in range(40,250)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print scipy.stats.describe(_heart_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(sorted(_heart_rates),bins=100, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bad heart rate numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(sorted(_bad_heart_rates),bins=100, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_speed = [ item[5] for sublist in endoHR for item in sublist['series'] if sublist['speed_included'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(sorted(_speed),bins=100, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print scipy.stats.describe(_speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No speed below zero, but seems unlikely someone got up to 235 MPH (assuming it is MPH, need to check. 235KM/h is just as unlikely). Lets look at it by sport "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for _i in exercise_types.keys():\n",
    "    _speed = [ item[5] for sublist in endoHR for item in sublist['series'] if sublist['speed_included'] == True and sublist['sport'] == _i]\n",
    "    print \"------\"\n",
    "    print _i\n",
    "    print len(_speed)\n",
    "    if len(_speed) == 0:\n",
    "        continue\n",
    "    plt.hist(sorted(_speed),bins=100, log=True)\n",
    "    plt.title(_i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Altitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_altitude = [ item[2] for sublist in endoHR for item in sublist['series'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(sorted(_altitude),bins=100, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print scipy.stats.describe(_altitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_high_altitude_locations = [item[3:5] for sublist in endoHR for item in sublist['series'] if item[2] > 3500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_high_altitude_locations[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # declare the center of the map, and how much we want the map zoomed in\n",
    "# gmap = gmplot.GoogleMapPlotter(0, 0, 2)\n",
    "# # plot heatmap\n",
    "# gmap.scatter([_i[0] for _i in _high_altitude_locations ],[_i[1] for _i in _high_altitude_locations ])\n",
    "\n",
    "# gmap.draw(\"/tmp/high_altitude_workout_locations.html\")\n",
    "\n",
    "_lat_longs = zip([_i[0] for _i in _high_altitude_locations ],[_i[1] for _i in _high_altitude_locations ])\n",
    "\n",
    "m = gmaps.Map()\n",
    "heatmap_layer = gmaps.Heatmap(data=_lat_longs)\n",
    "m.add_layer(heatmap_layer)\n",
    "\n",
    "heatmap_layer.max_intensity = 90\n",
    "heatmap_layer.point_radius = 3\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for _i in endoHR:\n",
    "    if len([1 for item in _i['series'] if item[2] > 5000]) > 0:\n",
    "        print _i['gender'], _i['id'], _i['sport'], _i['url'], _i['userId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check latitude and longitude\n",
    "\n",
    "#### Values should only between -90 / 90 & -180 / 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_latitude = [ item[3] for sublist in endoHR for item in sublist['series'] ]\n",
    "_longitude = [ item[4] for sublist in endoHR for item in sublist['series'] ]\n",
    "\n",
    "print scipy.stats.describe(_latitude)\n",
    "print scipy.stats.describe(_longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Check San DIego users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "sd_events = []\n",
    "for _endoHR in log_progress(endoHR):\n",
    "    _mid_point = []\n",
    "    \n",
    "    if len(_endoHR['series']) < 10:\n",
    "        continue\n",
    "        \n",
    "    _series = _endoHR['series']\n",
    "    _point = _series[len(_series) / 2]\n",
    "    \n",
    "    _lat = _point[3]\n",
    "    _long = _point[4]\n",
    "    \n",
    "    if _lat >= 32.4 and _lat <= 33.0 and _long <= -116.9 and _long >= -117.5:\n",
    "        sd_events.append(_endoHR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26 records near SD\n",
      "time: 1.49 ms\n"
     ]
    }
   ],
   "source": [
    "print \"Found %s records near SD\"%len(sd_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([3276737, 504709, 8888545, 7430612, 458903, 4226525])\n",
      "time: 1.52 ms\n"
     ]
    }
   ],
   "source": [
    "print set([ _i['userId'] for _i in sd_events ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 73.5 ms\n"
     ]
    }
   ],
   "source": [
    "_lat_longs = []\n",
    "for _endoHR in sd_events:\n",
    "    _series = _endoHR['series']\n",
    "    \n",
    "    [ _lat_longs.append([_i[3], _i[4]]) for _i in _series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9024"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.99 ms\n"
     ]
    }
   ],
   "source": [
    "len(_lat_longs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 284 ms\n"
     ]
    }
   ],
   "source": [
    "m = gmaps.Map()\n",
    "heatmap_layer = gmaps.Heatmap(data=_lat_longs)\n",
    "m.add_layer(heatmap_layer)\n",
    "\n",
    "heatmap_layer.max_intensity = 100\n",
    "heatmap_layer.point_radius = 5\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
